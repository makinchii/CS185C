{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc175c8-f744-4655-9037-b313c486c951",
   "metadata": {},
   "source": [
    "# Creating the Boundary Conditions\n",
    "\n",
    "This notebook serves as a demo for the creation of model boundary conditions. These boundary conditions are shown for Mike's Calfornia Current regional model. You can follow and/or adapt this notebook based on your configuration if you are using a regional domain.\n",
    "\n",
    "First, import packages to re-create and visualize the model fields here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f57c0-6983-48ce-b8a0-31c5b04463a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import netCDF4 as nc4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea649be-1868-47e6-a895-1cf4b03d5cdf",
   "metadata": {},
   "source": [
    "Next, define the location of the input directory for the model. This is the same directory that holds the bathymetry file generated in the previous notebooks for this model example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d8f138-1542-4af2-845e-ab0acad86dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input directory\n",
    "input_dir = 'C:\\\\Users\\\\azure\\\\Documents\\\\CS185C\\\\project\\\\input'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea43d2c-8106-4b7e-9d71-dda71ff556e4",
   "metadata": {},
   "source": [
    "## Constructing the Boundary Conditions\n",
    "For my model, I will use a model state from the ECCO Version 5 state estimate. I will prepare the boundary condition fields in 7 steps:\n",
    "1. download 5 fields and 4 grid files generated by the ECCO model in 2008\n",
    "2. read the ECCO model grid\n",
    "3. read in the bathymetry for my model as well as its grid\n",
    "4. prepare the ECCO fields for interpolation\n",
    "5. interpolate the ECCO fields onto my model grid and store each as a binary file\n",
    "6. plot the interpolated fields to ensure they look as expected\n",
    "7. prepare notes on the run-time options I will use to implement my approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5328af-a028-439b-a89a-4f39b72a9a65",
   "metadata": {},
   "source": [
    "### Step 1: Download the ECCO fields\n",
    "To begin, I downloaded the model fields generated by the ECCO Version 5 Alpha state estimate. These fields are available [HERE](https://ecco.jpl.nasa.gov/drive/files/Version5/Alpha/nctiles_monthly). In particular, I downloaded the following list of files that contain the field pertaining to time span of my model (2007, 2008, and 2009):\n",
    "\n",
    "| Variable | File Name |\n",
    "| -------- | --------- |\n",
    "|THETA|THETA/THETA_200[7-9].nc|\n",
    "|SALT|SALT/SALT_200[7-9].nc|\n",
    "|UVEL|UVELMASS/UVELMASS_200[7-9].nc|\n",
    "|VVEL|VVELMASS/VVELMASS_200[7-9].nc|\n",
    "\n",
    "I stored these fields in the following directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d9856c-ec0b-4f6e-9f9c-c18a73cd6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'C:\\\\Users\\\\azure\\\\Documents\\\\CS185C\\\\project\\\\data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d170a9e7-8862-4e25-b732-1268f2c77c5a",
   "metadata": {},
   "source": [
    "### Step 2: Read in the ECCO grid\n",
    "To read in the ECCO fields, I will rely on the `grid` module from the `eccoseas.ecco` package [HERE](https://github.com/mhwood/eccoseas), which I import here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d18072-c8a6-425f-a5f6-75dc2ffc43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eccoseas.ecco import grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925b6ec-93ab-429b-a830-d6591b15a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecco_XC_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='XC')\n",
    "ecco_YC_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='YC')\n",
    "ecco_hFacC_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='hFacC')\n",
    "ecco_hFacW_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='hFacW')\n",
    "ecco_hFacS_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='hFacS')\n",
    "ecco_RF_tiles = grid.read_ecco_grid_tiles_from_nc(data_folder, var_name='RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf96ac-d0e5-4e53-884f-16e0fec32152",
   "metadata": {},
   "source": [
    "As described [HERE](https://ecco-v4-python-tutorial.readthedocs.io/ECCO_v4_Plotting_Tiles.html), the ECCO grid has 13 tiles but only 1 or 2 may pertain to my local area. To determine which tiles correspond to my region, I'll read in my model grid next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a135ac-a5bb-4766-83b5-60039dcc0c56",
   "metadata": {},
   "source": [
    "### Step 3: Read in the Model Grid and Generate a Mask\n",
    "Here, I will recreate the grid I will use in my model and read in the bathymetry file (see previous notebooks for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b8cc3-eb40-40c3-b61e-1359d986109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameters that will be used in the data file\n",
    "delX = 1/12\n",
    "delY = 1/16\n",
    "xgOrigin = -135\n",
    "ygOrigin = 29\n",
    "n_rows = 360\n",
    "n_cols = 240\n",
    "\n",
    "# recreate the grids that will be used in the model\n",
    "xc = np.arange(xgOrigin+delX/2, xgOrigin+n_cols*delX, delX)\n",
    "yc = np.arange(ygOrigin+delY/2, ygOrigin+n_rows*delY, delY)\n",
    "XC, YC = np.meshgrid(xc, yc)\n",
    "\n",
    "# read in the bathymetry file\n",
    "bathy = np.fromfile(os.path.join(input_dir,'HLB_bathymetry.bin'),'>f4').reshape(np.shape(XC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd8e15a-b056-4c97-86b1-c3eb4c5e020c",
   "metadata": {},
   "source": [
    "With an eye toward the interpolation to come next, I will make a mask to determine where the interpolatation will take place. I will create this mask by recreating the `hFac` field for my model using the `hFac` module from the `eccoseas` package: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d4f4e-52b9-4ec4-b416-d033a4f94633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eccoseas.downscale import hFac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f9cf36-029c-431c-b2f0-5fe80a139c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = bathy\n",
    "delR = np.array([ 10.00, 10.00, 10.00, 10.00, 10.00, 10.00, 10.00, 10.01,\n",
    "                 10.03, 10.11, 10.32, 10.80, 11.76, 13.42, 16.04, 19.82, 24.85,\n",
    "                 31.10, 38.42, 46.50, 55.00, 63.50, 71.58, 78.90, 85.15, 90.18,\n",
    "                 93.96, 96.58, 98.25, 99.25,100.01,101.33,104.56,111.33,122.83,\n",
    "                 139.09,158.94,180.83,203.55,226.50,249.50,272.50,295.50,318.50,\n",
    "                 341.50,364.50,387.50,410.50,433.50,456.50,])\n",
    "Z = np.cumsum(delR)\n",
    "hFacC = hFac.create_hFacC_grid(depth, delR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb82b3d-ffa2-4312-916f-3325a0089c6b",
   "metadata": {},
   "source": [
    "The mask is generated by setting all of the non-zero `hFac` points to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dcfe0a-3641-43d7-99aa-88a48310eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.copy(hFacC)\n",
    "mask[mask>0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601f994-42b7-4840-8da4-73f98c9269f4",
   "metadata": {},
   "source": [
    "To double check the mask was created as expected, I will plot it in comparison to the bathymetry here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea1cb2-e29e-49c8-befe-eba9e857244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "C = plt.pcolormesh(XC, YC, bathy, vmin=-5000, vmax=0, cmap='Blues_r')\n",
    "plt.colorbar(C, orientation = 'horizontal')\n",
    "plt.title('Model Bathymetry')\n",
    "\n",
    "depth_level = 0\n",
    "plt.subplot(1,2,2)\n",
    "C = plt.pcolormesh(XC, YC, mask[0], vmin=0, vmax=1, cmap='Greys')\n",
    "plt.colorbar(C, orientation = 'horizontal')\n",
    "plt.title('Mask (depth level = '+str(depth_level))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5abdd9-4043-4967-9651-556a2d083e6c",
   "metadata": {},
   "source": [
    "Seems reasonable!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e0e64-13eb-4122-ae3c-0fead095fc9b",
   "metadata": {},
   "source": [
    "### Step 4: Prepare the grids for interpolation\n",
    "At this point, we can use the geometry of both grids to check to see which tiles have the information we need. After some trial and error (and referencing the ECCO page), I find that tiles 8 and 11 have the points I need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076dfc32-ab58-422e-9b5a-47985af1e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the ECCO tile points from tiles 8 and 11\n",
    "plt.plot(ecco_XC_tiles[11],ecco_YC_tiles[11],'k.')\n",
    "plt.plot(ecco_XC_tiles[8],ecco_YC_tiles[8],'k.')\n",
    "\n",
    "# plot the boundary of the CA model\n",
    "plt.plot(XC[:,0],YC[:,0], 'g-')\n",
    "plt.plot(XC[:,-1],YC[:,-1], 'g-')\n",
    "plt.plot(XC[0,:],YC[0,:], 'g-')\n",
    "plt.plot(XC[-1,:],YC[-1,:], 'g-')\n",
    "\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b332346e-acea-4d60-9494-8d850824b8f4",
   "metadata": {},
   "source": [
    "As we can see, my model boundary (green) is completely surrounded by the points in tile 8 and 11 (black). I also note that there is extraneous information in points with longitude greater than ~140 - I will omit these points as well. Given these observations, now I read in points from just those tiles to use in interpolation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5f5ec-1a41-4da6-81aa-9d121dfa023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_list = [8,11]\n",
    "\n",
    "# determine the number of points in each set\n",
    "total_points = 0\n",
    "for tile_number in tile_list:\n",
    "    total_points += np.size(ecco_XC_tiles[tile_number])\n",
    "\n",
    "# make empty arrays to fill in\n",
    "ecco_XC_points = np.zeros((total_points, ))\n",
    "ecco_YC_points = np.zeros((total_points, ))\n",
    "ecco_hFacC_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "ecco_hFacW_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "ecco_hFacS_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "ecco_mask_points = np.zeros((np.size(ecco_RF_tiles[1]) , total_points))\n",
    "\n",
    "# loop through the tiles and fill in the XC, YC, and mask points for interpolation\n",
    "points_counted = 0\n",
    "for tile_number in tile_list:\n",
    "    tile_N = np.size(ecco_XC_tiles[tile_number])\n",
    "    \n",
    "    ecco_XC_points[points_counted:points_counted+tile_N] = ecco_XC_tiles[tile_number].ravel()\n",
    "    ecco_YC_points[points_counted:points_counted+tile_N] = ecco_YC_tiles[tile_number].ravel()\n",
    "    \n",
    "    for k in range(np.size(ecco_RF_tiles[tile_number])):\n",
    "        level_hFacC = ecco_hFacC_tiles[tile_number][k, :, :]\n",
    "        level_hFacW = ecco_hFacW_tiles[tile_number][k, :, :]\n",
    "        level_hFacS = ecco_hFacS_tiles[tile_number][k, :, :]\n",
    "        level_mask = np.copy(level_hFacC)\n",
    "        level_mask[level_mask>0] = 1\n",
    "        ecco_hFacC_points[k, points_counted:points_counted+tile_N] = level_hFacC.ravel()\n",
    "        ecco_hFacW_points[k, points_counted:points_counted+tile_N] = level_hFacW.ravel()\n",
    "        ecco_hFacS_points[k, points_counted:points_counted+tile_N] = level_hFacS.ravel()\n",
    "        ecco_mask_points[k,points_counted:points_counted+tile_N] = level_mask.ravel()\n",
    "    \n",
    "    points_counted += tile_N\n",
    "\n",
    "# remove the points with positive longitude\n",
    "local_indices = ecco_XC_points<0\n",
    "ecco_mask_points = ecco_mask_points[:, local_indices]\n",
    "ecco_hFacC_points = ecco_hFacC_points[:, local_indices]\n",
    "ecco_hFacW_points = ecco_hFacW_points[:, local_indices]\n",
    "ecco_hFacS_points = ecco_hFacS_points[:, local_indices]\n",
    "ecco_YC_points = ecco_YC_points[local_indices]\n",
    "ecco_XC_points = ecco_XC_points[local_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4462677-8079-45e5-9faf-d39452350218",
   "metadata": {},
   "source": [
    "Next, we'll read in the real data fields and apply the modifications. First, create a dictionary to store the file names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb96e5-bef6-4307-a5b3-f4441a930f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a file dictionary to loop over\n",
    "\n",
    "year = 2008\n",
    "\n",
    "# test dictionary\n",
    "file_prefix_dict = {'THETA':'THETA_'+str(year)+'.nc'}\n",
    "\n",
    "# # once tested with the above dict, run and comment with this one\n",
    "file_prefix_dict = {'THETA':'THETA_'+str(year)+'.nc',\n",
    "                    'SALT':'SALT_'+str(year)+'.nc',\n",
    "                    'UVEL':'UVELMASS_'+str(year)+'.nc',\n",
    "                    'VVEL':'VVELMASS_'+str(year)+'.nc'}\n",
    "variable_names = list(file_prefix_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5206c-6f45-431e-9988-a1b007ce954e",
   "metadata": {},
   "source": [
    "Now, read the fields from the same tiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963b363-9245-4f9b-9f40-2b7318286460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list to hold all of the ECCO grids\n",
    "init_grids = []\n",
    "timesteps = 12 # data is monthly\n",
    "\n",
    "# loop through each variable to read in the grid\n",
    "for variable_name in variable_names:\n",
    "    \n",
    "    if variable_name == 'ETAN':\n",
    "        ds = nc4.Dataset(os.path.join(data_folder,file_prefix_dict[variable_name]))\n",
    "        grid = ds.variables[variable_name][:,:,:,:]\n",
    "        ds.close()\n",
    "    elif 'VEL' in variable_name:\n",
    "        ds = nc4.Dataset(os.path.join(data_folder,'UVELMASS_'+str(year)+'.nc'))\n",
    "        u_grid = ds.variables['UVELMASS'][:,:,:,:,:]\n",
    "        ds.close()\n",
    "        ds = nc4.Dataset(os.path.join(data_folder,'VVELMASS_'+str(year)+'.nc'))\n",
    "        v_grid = ds.variables['VVELMASS'][:,:,:,:,:]\n",
    "        ds.close()\n",
    "    else:\n",
    "        ds = nc4.Dataset(os.path.join(data_folder,file_prefix_dict[variable_name]))\n",
    "        grid = ds.variables[variable_name][:,:,:,:,:]\n",
    "        ds.close()\n",
    "    \n",
    "    # create a grid of zeros to fill in\n",
    "    N = np.shape(grid)[-1]*np.shape(grid)[-2]\n",
    "    if variable_name == 'ETAN':\n",
    "        init_grid = np.zeros((timesteps, 1, N*len(tile_list)))\n",
    "    else:\n",
    "        init_grid = np.zeros((timesteps, np.size(ecco_RF_tiles[1]), N*len(tile_list)))\n",
    "\n",
    "    # loop through the tiles\n",
    "    for t in range(timesteps):\n",
    "        points_counted = 0\n",
    "        for tile_number in tile_list:\n",
    "            if variable_name == 'ETAN':\n",
    "                init_grid[t, points_counted:points_counted+N] = \\\n",
    "                     grid[t, tile_number-1, :, :].ravel()\n",
    "            elif 'VEL' in variable_name: # when using velocity, need to consider the tile rotations\n",
    "                if variable_name == 'UVEL':\n",
    "                    if tile_number<7:\n",
    "                        for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                            init_grid[t, k,points_counted:points_counted+N] = \\\n",
    "                                 u_grid[t, k, tile_number-1, :, :].ravel()\n",
    "                    else:\n",
    "                        for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                            init_grid[t, k,points_counted:points_counted+N] = \\\n",
    "                                 v_grid[t, k, tile_number-1, :, :].ravel()\n",
    "                if variable_name == 'VVEL':\n",
    "                    if tile_number<7:\n",
    "                        for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                            init_grid[t,k,points_counted:points_counted+N] = \\\n",
    "                                 v_grid[t, k, tile_number-1, :, :].ravel()\n",
    "                    else:\n",
    "                        for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                            init_grid[t,k,points_counted:points_counted+N] = \\\n",
    "                                 -1*u_grid[t, k, tile_number-1, :, :].ravel()\n",
    "            else:\n",
    "                for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                    init_grid[t,k,points_counted:points_counted+N] = \\\n",
    "                     grid[t, k, tile_number-1, :, :].ravel()\n",
    "            points_counted += N\n",
    "\n",
    "    # remove the points with positive longitudes\n",
    "    init_grid = init_grid[:,:,local_indices]\n",
    "\n",
    "    # apply some corrections\n",
    "    if variable_name == 'UVEL':\n",
    "        for t in range(timesteps):\n",
    "            for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                non_zero_indices = ecco_hFacW_points[k,:]!=0\n",
    "                init_grid[t,k,non_zero_indices] = init_grid[t,k,non_zero_indices]/(ecco_hFacW_points[k,non_zero_indices])\n",
    "    if variable_name == 'VVEL':\n",
    "        for t in range(timesteps):\n",
    "            for k in range(np.size(ecco_RF_tiles[1])):\n",
    "                non_zero_indices = ecco_hFacS_points[k,:]!=0\n",
    "                init_grid[t,k,non_zero_indices] = init_grid[t,k,non_zero_indices]/(ecco_hFacS_points[k,non_zero_indices])\n",
    "    \n",
    "    init_grids.append(init_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e32043-a3a3-49df-a724-de2be9f98708",
   "metadata": {},
   "source": [
    "### Step 5: Interpolate the Fields onto the Model Grid\n",
    "Next, I will interpolate the ECCO external fields I read in onto my model domain. I will use the `horizonal` module from the `eccoseas` package to accomplish this interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c081d0-77ac-4aba-8af7-baeb749a9a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the boundary list for the model\n",
    "boundary_list = ['west','south','north']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05564d75-ab5b-48e1-87c8-d9c28e8fd432",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'obcs' not in os.listdir(input_dir):\n",
    "    os.mkdir(os.path.join(input_dir,'obcs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15f228-d61d-4a42-9714-ed5037711b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eccoseas.downscale import horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1028da-5a5b-4662-b772-73dadd97bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'obcs' not in os.listdir(input_dir):\n",
    "    os.mkdir(os.path.join(input_dir,'obcs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aae164-a3f8-470b-a973-7f7ddffdcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each boundary\n",
    "for boundary in boundary_list:\n",
    "\n",
    "    if boundary == 'west':\n",
    "        boundary_XC = XC[:,:1]\n",
    "        boundary_YC = YC[:,:1]\n",
    "        boundary_mask = mask[:,:,:1]\n",
    "    elif boundary == 'east':\n",
    "        boundary_XC = XC[:,-1:]\n",
    "        boundary_YC = YC[:,-1:]\n",
    "        boundary_mask = mask[:,:,-1:]\n",
    "    elif boundary == 'north':\n",
    "        boundary_XC = XC[-1:,:]\n",
    "        boundary_YC = YC[-1:,:]\n",
    "        boundary_mask = mask[:,-1:,:]\n",
    "    elif boundary == 'south':\n",
    "        boundary_XC = XC[:1,:]\n",
    "        boundary_YC = YC[:1,:]\n",
    "        boundary_mask = mask[:,:1,:]\n",
    "    else:\n",
    "        raise ValueError('Boundary '+boundary+' not recognized')\n",
    "\n",
    "    # loop through each variable and corresponding ECCO grid\n",
    "    for variable_name, init_grid in zip(variable_names, init_grids):\n",
    "\n",
    "        output_grid = np.zeros((timesteps, np.size(delR), np.size(boundary_XC)))\n",
    "    \n",
    "        # print a message to keep track of which variable we are working on\n",
    "        # uncomment to use\n",
    "        # print('    - Interpolating the '+variable_name+' grid')\n",
    "\n",
    "        for t in range(timesteps):\n",
    "            interpolated_grid = horizontal.downscale_3D_points(np.column_stack([ecco_XC_points, ecco_YC_points]),\n",
    "                                                               init_grid[t,:,:], ecco_mask_points, \n",
    "                                                               boundary_XC, boundary_YC, boundary_mask)\n",
    "            for k in range(len(delR)):\n",
    "                output_grid[t,k,:] = interpolated_grid[k,:,:].ravel()\n",
    "    \n",
    "        # output the interpolated grid\n",
    "        output_file = os.path.join(input_dir,'obcs',variable_name+'_'+boundary+'_'+str(year)\n",
    "        output_grid.ravel('C').astype('>f4').tofile(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe30ee2-7b83-498d-813c-9b9ea152ed6f",
   "metadata": {},
   "source": [
    "### Step 6: Plotting the Boundary Fields\n",
    "Now that the fields have been generated, I will plot them to ensure they look as expected. First, I'll generate some metadata for each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac447d-91d1-4a85-b4c3-12529580db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_dict = {'THETA':[6, 18, 'turbo', 'm'],\n",
    "            'SALT':[32, 35, 'viridis', 'm'],\n",
    "            'UVEL':[-0.1, 0.1, 'seismic', 'm'],\n",
    "            'VVEL':[-0.1, 0.1, 'seismic', 'm']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60e704-57ae-4d35-aca8-2dbc8ad5f84a",
   "metadata": {},
   "source": [
    "Then, I'll create all of the subplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd252056-d8e7-4cce-a50d-43e20b50c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "\n",
    "plot_counter = 0\n",
    "for i in range(len(variable_names)):\n",
    "    variable_name = variable_names[i]\n",
    "    \n",
    "    for boundary in boundary_list:\n",
    "        \n",
    "        boundary_grid = np.fromfile(os.path.join(input_dir,'obcs',variable_name+'_'+boundary+'_2008'),'>f4')\n",
    "    \n",
    "        if boundary in ['west','east']:\n",
    "            boundary_grid = boundary_grid.reshape((timesteps, np.shape(delR)[0],np.shape(XC)[0]))\n",
    "            boundary_grid = boundary_grid[0, :, :] # choose just the first timestep for plotting\n",
    "            if boundary=='west':\n",
    "                x = YC[:,1]\n",
    "            if boundary=='east':\n",
    "                x = YC[:,-1]\n",
    "        else:\n",
    "            boundary_grid = boundary_grid.reshape((timesteps, np.shape(delR)[0],np.shape(XC)[1]))\n",
    "            boundary_grid = boundary_grid[0, :, :] # choose just the first timestep for plotting\n",
    "            if boundary=='north':\n",
    "                x = XC[-1,:]\n",
    "            if boundary=='south':\n",
    "                x = XC[1,:]\n",
    "\n",
    "        plot_counter += 1\n",
    "        plt.subplot(len(variable_names),len(boundary_list),plot_counter)\n",
    "        C = plt.pcolormesh(x, Z, boundary_grid,\n",
    "                           vmin=meta_dict[variable_names[i]][0],\n",
    "                           vmax=meta_dict[variable_names[i]][1],\n",
    "                           cmap=meta_dict[variable_names[i]][2])\n",
    "        plt.colorbar(C,fraction=0.26)\n",
    "        plt.gca().invert_yaxis()\n",
    "    \n",
    "        if plot_counter%3==1:\n",
    "            plt.ylabel(variable_name)\n",
    "        if plot_counter<4:\n",
    "            plt.title(boundary)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ea7f2-2254-47f8-989b-04990088b89a",
   "metadata": {},
   "source": [
    "Looks good! Now, with the initial conditions, external forcing conditions, and boundary conditions we are nearly ready to start testing the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeeedb0-d365-4e6a-a6e1-222351fa222f",
   "metadata": {},
   "source": [
    "### Step 7: Run-time considerations\n",
    "To use the grids as boundary conditions in the model, I will use the `obcs` package - short for Open Boundary Condtions. To ensure the boundary conditions are included in the model, I will add a line for `obcs` in my `code/packages.conf` compile time file.\n",
    "\n",
    "Next, I will add a line with ` useOBCS=.TRUE.` to the `data.pkg` file and a new file called `data.obcs` to my run directory. See Canvas for an editable `data.obcs` file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
